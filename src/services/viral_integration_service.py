#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ARQV30 Enhanced v3.0 - Viral Integration Service
Servi√ßo para integrar com o app viral (Cloudflare Worker)
"""

import os
import logging
import asyncio
import aiohttp
import json
import time
from typing import Dict, List, Any, Optional
from datetime import datetime
from pathlib import Path
import requests
from urllib.parse import urlparse

logger = logging.getLogger(__name__)

class ViralIntegrationService:
    """Servi√ßo para integrar com o app viral"""

    def __init__(self):
        """Inicializa o servi√ßo de integra√ß√£o viral"""
        # URL do worker viral - pode ser configurada via vari√°vel de ambiente
        self.viral_worker_url = os.getenv('VIRAL_WORKER_URL', 'http://localhost:8787')
        self.timeout = 30
        self.max_retries = 3
        
        # Diret√≥rio para salvar imagens
        self.images_dir = Path("analyses_data/viral_images")
        self.images_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"üî• Viral Integration Service inicializado - URL: {self.viral_worker_url}")

    async def search_viral_content(
        self,
        query: str,
        session_id: str,
        max_images: int = 20,
        min_engagement: int = 50,
        platforms: List[str] = None
    ) -> Dict[str, Any]:
        """Busca conte√∫do viral usando o worker"""
        
        if platforms is None:
            platforms = ['instagram', 'facebook']
        
        logger.info(f"üîç Buscando conte√∫do viral para: {query}")
        
        search_payload = {
            "query": query,
            "max_images": max_images,
            "min_engagement": min_engagement,
            "platforms": platforms
        }
        
        # Primeiro tenta verificar se o servi√ßo viral est√° dispon√≠vel
        if not await self._check_viral_service_health():
            logger.warning("‚ö†Ô∏è Servi√ßo viral n√£o dispon√≠vel, tentando m√©todo alternativo")
            # Tenta m√©todo s√≠ncrono como fallback
            return await self._search_viral_sync_fallback(query, session_id, search_payload)
        
        # Tenta m√∫ltiplas vezes com diferentes configura√ß√µes
        for attempt in range(self.max_retries):
            try:
                # Configura√ß√£o mais robusta para conex√µes locais
                connector = aiohttp.TCPConnector(
                    limit=10,
                    limit_per_host=5,
                    ttl_dns_cache=300,
                    use_dns_cache=True,
                    keepalive_timeout=30,
                    enable_cleanup_closed=True
                )
                
                timeout = aiohttp.ClientTimeout(
                    total=15,  # Timeout menor
                    connect=5,
                    sock_read=10
                )
                
                async with aiohttp.ClientSession(
                    connector=connector,
                    timeout=timeout
                ) as session:
                    logger.info(f"üîÑ Tentativa {attempt + 1}/{self.max_retries} de conex√£o viral")
                    
                    async with session.post(
                        f"{self.viral_worker_url}/api/search",
                        json=search_payload,
                        headers={
                            'Content-Type': 'application/json',
                            'User-Agent': 'V70V1-ViralIntegration/1.0'
                        }
                    ) as response:
                        
                        if response.status == 200:
                            result = await response.json()
                            logger.info(f"‚úÖ Viral search conclu√≠da - {len(result.get('images', []))} imagens encontradas")
                            
                            # Processa e salva imagens localmente
                            processed_result = await self._process_viral_results(result, session_id)
                            return processed_result
                        else:
                            error_text = await response.text()
                            logger.error(f"‚ùå Erro na busca viral (tentativa {attempt + 1}): {response.status} - {error_text}")
                            
                            if attempt == self.max_retries - 1:
                                return self._create_fallback_result(query, session_id)
                            
                            # Aguarda antes da pr√≥xima tentativa
                            await asyncio.sleep(2 ** attempt)
                            continue
                            
            except (asyncio.TimeoutError, aiohttp.ClientError) as e:
                logger.error(f"‚è∞ Erro de conex√£o viral (tentativa {attempt + 1}): {e}")
                if attempt == self.max_retries - 1:
                    return self._create_fallback_result(query, session_id)
                await asyncio.sleep(2 ** attempt)
                continue
                
            except Exception as e:
                logger.error(f"‚ùå Erro inesperado na integra√ß√£o viral (tentativa {attempt + 1}): {e}")
                if attempt == self.max_retries - 1:
                    return self._create_fallback_result(query, session_id)
                await asyncio.sleep(2 ** attempt)
                continue

    async def _check_viral_service_health(self) -> bool:
        """Verifica se o servi√ßo viral est√° dispon√≠vel"""
        try:
            # Usa requests s√≠ncrono para verifica√ß√£o r√°pida
            import requests
            response = requests.get(
                f"{self.viral_worker_url}/api/searches",
                timeout=5,
                headers={'User-Agent': 'V70V1-HealthCheck/1.0'}
            )
            
            if response.status_code in [200, 404]:  # 404 √© OK, significa que o servi√ßo est√° rodando
                logger.info("‚úÖ Servi√ßo viral est√° dispon√≠vel")
                return True
            else:
                logger.warning(f"‚ö†Ô∏è Servi√ßo viral retornou status {response.status_code}")
                return False
                
        except requests.exceptions.ConnectionError:
            logger.warning("‚ö†Ô∏è N√£o foi poss√≠vel conectar ao servi√ßo viral")
            return False
        except requests.exceptions.Timeout:
            logger.warning("‚ö†Ô∏è Timeout ao verificar servi√ßo viral")
            return False
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao verificar servi√ßo viral: {e}")
            return False

    async def _search_viral_sync_fallback(self, query: str, session_id: str, search_payload: Dict[str, Any]) -> Dict[str, Any]:
        """M√©todo s√≠ncrono de fallback para busca viral"""
        try:
            logger.info("üîÑ Tentando busca viral com m√©todo s√≠ncrono")
            
            import requests
            response = requests.post(
                f"{self.viral_worker_url}/api/search",
                json=search_payload,
                headers={
                    'Content-Type': 'application/json',
                    'User-Agent': 'V70V1-SyncFallback/1.0'
                },
                timeout=15
            )
            
            if response.status_code == 200:
                result = response.json()
                logger.info(f"‚úÖ Viral search s√≠ncrona conclu√≠da - {len(result.get('images', []))} imagens encontradas")
                
                # Processa e salva imagens localmente
                processed_result = await self._process_viral_results(result, session_id)
                return processed_result
            else:
                logger.error(f"‚ùå Erro na busca viral s√≠ncrona: {response.status_code} - {response.text}")
                return self._create_fallback_result(query, session_id)
                
        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå Erro de conex√£o na busca viral s√≠ncrona: {e}")
            return self._create_fallback_result(query, session_id)
        except Exception as e:
            logger.error(f"‚ùå Erro inesperado na busca viral s√≠ncrona: {e}")
            return self._create_fallback_result(query, session_id)

    async def _process_viral_results(self, viral_result: Dict[str, Any], session_id: str) -> Dict[str, Any]:
        """Processa resultados do viral e salva imagens localmente"""
        
        processed_images = []
        session_images_dir = self.images_dir / session_id
        session_images_dir.mkdir(parents=True, exist_ok=True)
        
        images = viral_result.get('images', [])
        
        for i, image_data in enumerate(images):
            try:
                # Baixa e salva a imagem localmente
                local_image_path = await self._download_and_save_image(
                    image_data.get('image_url', ''),
                    session_images_dir,
                    f"viral_image_{i+1}_{int(time.time())}"
                )
                
                # Adiciona informa√ß√µes processadas
                processed_image = {
                    'id': f"viral_{session_id}_{i+1}",
                    'title': image_data.get('title', 'Conte√∫do Viral'),
                    'description': image_data.get('description', ''),
                    'platform': image_data.get('platform', 'unknown'),
                    'engagement_score': image_data.get('engagement_score', 0),
                    'views_estimate': image_data.get('views_estimate', 0),
                    'likes_estimate': image_data.get('likes_estimate', 0),
                    'comments_estimate': image_data.get('comments_estimate', 0),
                    'shares_estimate': image_data.get('shares_estimate', 0),
                    'author': image_data.get('author', 'Desconhecido'),
                    'author_followers': image_data.get('author_followers', 0),
                    'post_date': image_data.get('post_date', datetime.now().isoformat()),
                    'hashtags': image_data.get('hashtags', []),
                    'original_url': image_data.get('post_url', ''),
                    'image_url': image_data.get('image_url', ''),
                    'local_image_path': str(local_image_path) if local_image_path else None,
                    'collected_at': datetime.now().isoformat()
                }
                
                processed_images.append(processed_image)
                
            except Exception as e:
                logger.error(f"‚ùå Erro ao processar imagem viral {i+1}: {e}")
                continue
        
        # Calcula m√©tricas agregadas
        total_engagement = sum(img.get('engagement_score', 0) for img in processed_images)
        total_views = sum(img.get('views_estimate', 0) for img in processed_images)
        total_likes = sum(img.get('likes_estimate', 0) for img in processed_images)
        
        platforms_found = list(set(img.get('platform', 'unknown') for img in processed_images))
        
        return {
            'session_id': session_id,
            'search_completed_at': datetime.now().isoformat(),
            'total_images_found': len(processed_images),
            'total_images_saved': len([img for img in processed_images if img.get('local_image_path')]),
            'platforms_searched': platforms_found,
            'viral_images': processed_images,
            'aggregated_metrics': {
                'total_engagement_score': total_engagement,
                'average_engagement': total_engagement / len(processed_images) if processed_images else 0,
                'total_estimated_views': total_views,
                'total_estimated_likes': total_likes,
                'top_performing_platform': max(platforms_found, key=lambda p: len([img for img in processed_images if img.get('platform') == p])) if platforms_found else 'none'
            },
            'original_viral_result': viral_result
        }

    async def _download_and_save_image(self, image_url: str, save_dir: Path, filename_base: str) -> Optional[Path]:
        """Baixa e salva uma imagem localmente"""
        
        if not image_url:
            return None
            
        try:
            # Determina extens√£o da imagem
            parsed_url = urlparse(image_url)
            path_parts = parsed_url.path.split('.')
            extension = path_parts[-1].lower() if len(path_parts) > 1 and path_parts[-1].lower() in ['jpg', 'jpeg', 'png', 'gif', 'webp'] else 'jpg'
            
            filename = f"{filename_base}.{extension}"
            file_path = save_dir / filename
            
            # Baixa a imagem
            async with aiohttp.ClientSession() as session:
                async with session.get(image_url, timeout=aiohttp.ClientTimeout(total=10)) as response:
                    if response.status == 200:
                        content = await response.read()
                        
                        # Salva o arquivo
                        with open(file_path, 'wb') as f:
                            f.write(content)
                        
                        logger.info(f"‚úÖ Imagem salva: {file_path}")
                        return file_path
                    else:
                        logger.warning(f"‚ö†Ô∏è Falha ao baixar imagem: {response.status}")
                        return None
                        
        except Exception as e:
            logger.error(f"‚ùå Erro ao baixar imagem {image_url}: {e}")
            return None

    def _create_fallback_result(self, query: str, session_id: str) -> Dict[str, Any]:
        """Cria resultado de fallback quando a integra√ß√£o viral falha"""
        
        logger.warning("‚ö†Ô∏è Usando resultado de fallback para viral")
        
        return {
            'session_id': session_id,
            'search_completed_at': datetime.now().isoformat(),
            'total_images_found': 0,
            'total_images_saved': 0,
            'platforms_searched': [],
            'viral_images': [],
            'aggregated_metrics': {
                'total_engagement_score': 0,
                'average_engagement': 0,
                'total_estimated_views': 0,
                'total_estimated_likes': 0,
                'top_performing_platform': 'none'
            },
            'error': 'Falha na integra√ß√£o com o servi√ßo viral',
            'fallback_used': True,
            'original_query': query
        }

    def get_viral_search_history(self, limit: int = 20) -> List[Dict[str, Any]]:
        """Obt√©m hist√≥rico de buscas virais (se o worker estiver dispon√≠vel)"""
        
        try:
            response = requests.get(
                f"{self.viral_worker_url}/api/searches",
                timeout=10
            )
            
            if response.status_code == 200:
                return response.json()[:limit]
            else:
                logger.warning(f"‚ö†Ô∏è Falha ao obter hist√≥rico viral: {response.status_code}")
                return []
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao obter hist√≥rico viral: {e}")
            return []

    def get_viral_search_by_id(self, search_id: str) -> Optional[Dict[str, Any]]:
        """Obt√©m resultado de busca viral espec√≠fica por ID"""
        
        try:
            response = requests.get(
                f"{self.viral_worker_url}/api/search/{search_id}",
                timeout=10
            )
            
            if response.status_code == 200:
                return response.json()
            else:
                logger.warning(f"‚ö†Ô∏è Busca viral {search_id} n√£o encontrada: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao obter busca viral {search_id}: {e}")
            return None

# Inst√¢ncia global do servi√ßo
viral_integration_service = ViralIntegrationService()